{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import pathlib \n",
    "\n",
    "def load_train_val_data(image_size=(384, 512), batch_size=16):\n",
    "    base_dir = pathlib.Path('..')\n",
    "    data_train = base_dir / 'data' / 'train'\n",
    "    print('Loading data')\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        '../data/train',\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        label_mode='categorical',\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_train,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        label_mode='categorical',\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Found 1766 files belonging to 6 classes.\n",
      "Using 1413 files for training.\n",
      "Found 1766 files belonging to 6 classes.\n",
      "Using 353 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = load_train_val_data(image_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "img_augmentation = tf.keras.models.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = img_augmentation(inputs)\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "model = build_model(num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "89/89 - 27s - loss: 1.4343 - accuracy: 0.7183 - val_loss: 0.8002 - val_accuracy: 0.7394 - 27s/epoch - 303ms/step\n",
      "Epoch 2/5\n",
      "89/89 - 18s - loss: 0.7602 - accuracy: 0.8436 - val_loss: 0.7885 - val_accuracy: 0.7904 - 18s/epoch - 202ms/step\n",
      "Epoch 3/5\n",
      "89/89 - 18s - loss: 0.8869 - accuracy: 0.8351 - val_loss: 0.9491 - val_accuracy: 0.8159 - 18s/epoch - 200ms/step\n",
      "Epoch 4/5\n",
      "89/89 - 18s - loss: 0.6891 - accuracy: 0.8754 - val_loss: 1.2008 - val_accuracy: 0.7904 - 18s/epoch - 200ms/step\n",
      "Epoch 5/5\n",
      "89/89 - 18s - loss: 0.6103 - accuracy: 0.8825 - val_loss: 1.1810 - val_accuracy: 0.8300 - 18s/epoch - 200ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "hist = model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ea4f19c824cf2ed3e82384cf55cc39a6ff5e215806f3b52e3e8a999134071f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('Garbage_classification-zsuLYxXv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
